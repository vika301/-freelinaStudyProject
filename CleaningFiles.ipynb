{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7faab919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the Concatinated Dataset is: 5646\n",
      "The size of the Cleaned Dataset is: 2100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#add path to concatinated files; here its the current one\n",
    "path=os.getcwd(r'Concatinated.csv')\n",
    "#give path and name result file\n",
    "savepath=os.getcwd(r'Cleaned.csv')\n",
    "file= pd.read_csv(path)\n",
    "# print the size of the dataset before cleaning\n",
    "print(\"The size of the Concatinated Dataset is:\", len(file))\n",
    "cleaned = file.drop_duplicates('id')\n",
    "#get info about the dataset\n",
    "#cleaned.info()\n",
    "#print the size of the dataset afte cleaning form duplicates\n",
    "print(\"The size of the Cleaned Dataset is:\", len(cleaned))\n",
    "#save dataset\n",
    "cleaned.to_csv(savepath, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ffaf7cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 51.75812830999441\n",
      "mean: 32.30769230769231\n",
      "median: 13.0\n",
      "date\n",
      "2021-03-28      1\n",
      "2021-05-18      1\n",
      "2021-06-02      1\n",
      "2021-09-08      1\n",
      "2021-10-28      1\n",
      "2022-03-20      1\n",
      "2022-05-10      1\n",
      "2022-05-11      1\n",
      "2022-05-12      1\n",
      "2022-05-13      1\n",
      "2022-05-16      1\n",
      "2022-05-24      1\n",
      "2022-05-26      1\n",
      "2022-05-28      5\n",
      "2022-05-29      2\n",
      "2022-05-30     77\n",
      "2022-05-31    162\n",
      "2022-06-01    100\n",
      "2022-06-02    158\n",
      "2022-06-03    217\n",
      "2022-06-04    104\n",
      "2022-06-05     24\n",
      "2022-06-06     22\n",
      "2022-06-07      3\n",
      "2022-06-08     13\n",
      "2022-06-09     43\n",
      "2022-06-10     17\n",
      "2022-06-11      1\n",
      "2022-06-12      8\n",
      "2022-06-13      6\n",
      "2022-06-14      3\n",
      "2022-06-15    242\n",
      "2022-06-16    168\n",
      "2022-06-17     45\n",
      "2022-06-18      9\n",
      "2022-06-19     28\n",
      "2022-06-20     14\n",
      "2022-06-21     23\n",
      "2022-06-22     26\n",
      "2022-06-23     19\n",
      "2022-06-24     10\n",
      "2022-06-25      7\n",
      "2022-06-26      5\n",
      "2022-06-27      5\n",
      "2022-06-28     15\n",
      "2022-06-29     72\n",
      "2022-06-30     36\n",
      "2022-07-01      4\n",
      "2022-07-02     31\n",
      "2022-07-03     13\n",
      "2022-07-04      4\n",
      "2022-07-05     39\n",
      "2022-07-06     24\n",
      "2022-07-07     12\n",
      "2022-07-08     15\n",
      "2022-07-09     45\n",
      "2022-07-10     36\n",
      "2022-07-11     53\n",
      "2022-07-12     26\n",
      "2022-07-13      7\n",
      "2022-07-14     21\n",
      "2022-07-15     32\n",
      "2022-07-16     11\n",
      "2022-07-17     12\n",
      "2022-07-18     13\n",
      "dtype: int64\n",
      "lang\n",
      "ar        6\n",
      "de     1710\n",
      "el        3\n",
      "en      157\n",
      "es        1\n",
      "fr        6\n",
      "in        2\n",
      "it        2\n",
      "nl        1\n",
      "no        6\n",
      "pt        1\n",
      "qht      41\n",
      "qme      65\n",
      "ro        2\n",
      "sv        1\n",
      "tl        1\n",
      "tr        6\n",
      "und      88\n",
      "zxx       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "'''get timepoints'''\n",
    "dup = cleaned\n",
    "\n",
    "timepoints= dup.local_time\n",
    "# take only the date into account and add it as a column to the dataframe\n",
    "time = dup.local_time.str[0:10]\n",
    "df= copy.copy(dup)\n",
    "df.head()\n",
    "df['date'] = time\n",
    "#pivot the dataframe over dates : add values of each day together day \n",
    "days= df.pivot_table(index = ['date'], aggfunc ='size')\n",
    "# get the mean, standarddeviation and median of the daily activity\n",
    "print(\"std:\",days.std())\n",
    "print(\"mean:\",days.mean())\n",
    "print(\"median:\",days.median())\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(days)\n",
    "'''get different languages'''\n",
    "languages= df.pivot_table(index = ['lang'], aggfunc ='size')\n",
    "#display languages and amount of used\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(languages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23a00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eaf893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
